{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95534aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\chiku\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\chiku\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import re\n",
    "import os\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download(\"stopwords\")\n",
    "stopset = set(w.upper() for w in stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb697c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv(r\"C:\\Users\\chiku\\OneDrive\\Documents\\blackcoffer\\Data Science-20211101T162608Z-001\\Data Science\\cik_list.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "684b35c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIK</th>\n",
       "      <th>CONAME</th>\n",
       "      <th>FYRMO</th>\n",
       "      <th>FDATE</th>\n",
       "      <th>FORM</th>\n",
       "      <th>SECFNAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3662.0</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199803.0</td>\n",
       "      <td>06-03-1998</td>\n",
       "      <td>10-K405</td>\n",
       "      <td>edgar/data/3662/0000950170-98-000413.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3662.0</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199805.0</td>\n",
       "      <td>15-05-1998</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>edgar/data/3662/0000950170-98-001001.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3662.0</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199808.0</td>\n",
       "      <td>13-08-1998</td>\n",
       "      <td>NT 10-Q</td>\n",
       "      <td>edgar/data/3662/0000950172-98-000783.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3662.0</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199811.0</td>\n",
       "      <td>12-11-1998</td>\n",
       "      <td>10-K/A</td>\n",
       "      <td>edgar/data/3662/0000950170-98-002145.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3662.0</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199811.0</td>\n",
       "      <td>16-11-1998</td>\n",
       "      <td>NT 10-Q</td>\n",
       "      <td>edgar/data/3662/0000950172-98-001203.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CIK            CONAME     FYRMO       FDATE     FORM  \\\n",
       "0  3662.0  SUNBEAM CORP/FL/  199803.0  06-03-1998  10-K405   \n",
       "1  3662.0  SUNBEAM CORP/FL/  199805.0  15-05-1998     10-Q   \n",
       "2  3662.0  SUNBEAM CORP/FL/  199808.0  13-08-1998  NT 10-Q   \n",
       "3  3662.0  SUNBEAM CORP/FL/  199811.0  12-11-1998   10-K/A   \n",
       "4  3662.0  SUNBEAM CORP/FL/  199811.0  16-11-1998  NT 10-Q   \n",
       "\n",
       "                                   SECFNAME  \n",
       "0  edgar/data/3662/0000950170-98-000413.txt  \n",
       "1  edgar/data/3662/0000950170-98-001001.txt  \n",
       "2  edgar/data/3662/0000950172-98-000783.txt  \n",
       "3  edgar/data/3662/0000950170-98-002145.txt  \n",
       "4  edgar/data/3662/0000950172-98-001203.txt  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2eb40bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIK</th>\n",
       "      <th>CONAME</th>\n",
       "      <th>FYRMO</th>\n",
       "      <th>FDATE</th>\n",
       "      <th>FORM</th>\n",
       "      <th>SECFNAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3662.0</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199803.0</td>\n",
       "      <td>06-03-1998</td>\n",
       "      <td>10-K405</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/3662/0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3662.0</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199805.0</td>\n",
       "      <td>15-05-1998</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/3662/0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3662.0</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199808.0</td>\n",
       "      <td>13-08-1998</td>\n",
       "      <td>NT 10-Q</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/3662/0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3662.0</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199811.0</td>\n",
       "      <td>12-11-1998</td>\n",
       "      <td>10-K/A</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/3662/0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3662.0</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199811.0</td>\n",
       "      <td>16-11-1998</td>\n",
       "      <td>NT 10-Q</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/3662/0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CIK            CONAME     FYRMO       FDATE     FORM  \\\n",
       "0  3662.0  SUNBEAM CORP/FL/  199803.0  06-03-1998  10-K405   \n",
       "1  3662.0  SUNBEAM CORP/FL/  199805.0  15-05-1998     10-Q   \n",
       "2  3662.0  SUNBEAM CORP/FL/  199808.0  13-08-1998  NT 10-Q   \n",
       "3  3662.0  SUNBEAM CORP/FL/  199811.0  12-11-1998   10-K/A   \n",
       "4  3662.0  SUNBEAM CORP/FL/  199811.0  16-11-1998  NT 10-Q   \n",
       "\n",
       "                                            SECFNAME  \n",
       "0  https://www.sec.gov/Archives/edgar/data/3662/0...  \n",
       "1  https://www.sec.gov/Archives/edgar/data/3662/0...  \n",
       "2  https://www.sec.gov/Archives/edgar/data/3662/0...  \n",
       "3  https://www.sec.gov/Archives/edgar/data/3662/0...  \n",
       "4  https://www.sec.gov/Archives/edgar/data/3662/0...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link = 'https://www.sec.gov/Archives/'\n",
    "data.SECFNAME = link+data.SECFNAME\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d803af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIK</th>\n",
       "      <th>CONAME</th>\n",
       "      <th>FYRMO</th>\n",
       "      <th>FDATE</th>\n",
       "      <th>FORM</th>\n",
       "      <th>SECFNAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3662.0</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199803.0</td>\n",
       "      <td>06-03-1998</td>\n",
       "      <td>10-K405</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/3662/0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3662.0</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199805.0</td>\n",
       "      <td>15-05-1998</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/3662/0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3662.0</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199808.0</td>\n",
       "      <td>13-08-1998</td>\n",
       "      <td>NT 10-Q</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/3662/0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3662.0</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199811.0</td>\n",
       "      <td>12-11-1998</td>\n",
       "      <td>10-K/A</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/3662/0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3662.0</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199811.0</td>\n",
       "      <td>16-11-1998</td>\n",
       "      <td>NT 10-Q</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/3662/0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CIK            CONAME     FYRMO       FDATE     FORM  \\\n",
       "0  3662.0  SUNBEAM CORP/FL/  199803.0  06-03-1998  10-K405   \n",
       "1  3662.0  SUNBEAM CORP/FL/  199805.0  15-05-1998     10-Q   \n",
       "2  3662.0  SUNBEAM CORP/FL/  199808.0  13-08-1998  NT 10-Q   \n",
       "3  3662.0  SUNBEAM CORP/FL/  199811.0  12-11-1998   10-K/A   \n",
       "4  3662.0  SUNBEAM CORP/FL/  199811.0  16-11-1998  NT 10-Q   \n",
       "\n",
       "                                            SECFNAME  \n",
       "0  https://www.sec.gov/Archives/edgar/data/3662/0...  \n",
       "1  https://www.sec.gov/Archives/edgar/data/3662/0...  \n",
       "2  https://www.sec.gov/Archives/edgar/data/3662/0...  \n",
       "3  https://www.sec.gov/Archives/edgar/data/3662/0...  \n",
       "4  https://www.sec.gov/Archives/edgar/data/3662/0...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94fa184a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string, unicodedata\n",
    "\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1dc7a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding more stopwords from text file of stopwords\n",
    "\n",
    "\n",
    "import glob\n",
    "path = \"StopWords*.txt\"\n",
    "glob.glob(path)\n",
    "for filename in glob.glob(path):\n",
    "    with open(filename, 'r') as f:\n",
    "        text = f.read()\n",
    "        text = re.sub(r\"\\s+\\|\\s+[\\w]*\" , \"\", text)        \n",
    "        stopset.update(text.upper().split())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6fca182a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cmudict to\n",
      "[nltk_data]     C:\\Users\\chiku\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package cmudict is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# syllables count (will be used in complex word count)\n",
    "from nltk.corpus import cmudict\n",
    "nltk.download('cmudict')\n",
    "d = cmudict.dict()\n",
    "\n",
    "def syllables(word):\n",
    "    #referred from stackoverflow.com/questions/14541303/count-the-number-of-syllables-in-a-word\n",
    "    count = 0\n",
    "    vowels = 'aeiouy'\n",
    "    word = word.lower()\n",
    "    if word[0] in vowels:\n",
    "        count +=1\n",
    "    for index in range(1,len(word)):\n",
    "        if word[index] in vowels and word[index-1] not in vowels:\n",
    "            count +=1\n",
    "    if word.endswith('e'):\n",
    "        count -= 1\n",
    "    if word.endswith('le'):\n",
    "        count+=1\n",
    "    if count == 0:\n",
    "        count +=1\n",
    "    return count\n",
    "\n",
    "def nsyl(word):\n",
    "    try:\n",
    "        return max([len(list(y for y in x if y[-1].isdigit())) for x in d[word.lower()]])\n",
    "    except KeyError:\n",
    "        #if word not found in cmudict\n",
    "        return syllables(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a747b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other usefull functions\n",
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "\n",
    "def remove_digits(text):\n",
    "    return re.sub('[\\d%/$]', '', text)\n",
    "\n",
    "def denoise_text(text):\n",
    "    text = strip_html(text)\n",
    "    text = remove_between_square_brackets(text)\n",
    "    text = remove_digits(text)\n",
    "    return text\n",
    "\n",
    "def remove_non_ascii(words):\n",
    "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def to_upper_case(words):\n",
    "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = word.upper()\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stopset:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def normalize(words):\n",
    "    words = remove_non_ascii(words)\n",
    "    words = to_upper_case(words)\n",
    "    words = remove_punctuation(words)\n",
    "\n",
    "    words = remove_stopwords(words)\n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48a085df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# section names\n",
    "MDA = \"Management's Discussion and Analysis\"\n",
    "QQDMR = \"Quantitative and Qualitative Disclosures about Market Risk\"\n",
    "RF = \"Risk Factors\"\n",
    "section_name = ['MDA','QQDMR',\"RF\"]\n",
    "section = [MDA.upper(),QQDMR.upper(),RF.upper()]\n",
    "variables = ['positive_score','negative_score','polarity_score','average_sentence_length', 'percentage_of_complex_words',\\\n",
    "                   'fog_index','complex_word_count','word_count','uncertainty_score','constraining_score', 'positive_word_proportion',\\\n",
    "                   'negative_word_proportion', 'uncertainty_word_proportion', 'constraining_word_proportion' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "983a6c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-a5777f2468a2>:3: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  constraining_words_whole_report = pd.Series(name='constraining_words_whole_report')\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "constraining_words_whole_report = pd.Series(name='constraining_words_whole_report')\n",
    "\n",
    "df_col = [sec.lower() + '_' + var for sec,var in itertools.product(section_name,variables) ]\n",
    "df = pd.DataFrame(columns=df_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "baa4eff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 42)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a27365",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "058bf91f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-32-57723df4e9d1>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-32-57723df4e9d1>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    master_dict = pd.read_excel(rC:\\Users\\chiku\\OneDrive\\Documents\\blackcoffer\\Data Science-20211101T162608Z-001\\Data Science\\LoughranMcDonald_MasterDictionary_2018.xlsx\")\u001b[0m\n\u001b[1;37m                                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#usefull dictionaries\n",
    "master_dict = pd.read_excel(r\"C:\\Users\\chiku\\OneDrive\\Documents\\blackcoffer\\Data Science-20211101T162608Z-001\\Data Science\\LoughranMcDonald_MasterDictionary_2018.xlsx\")\n",
    "\n",
    "constraining_dict = set(pd.read_excel('./constraining_dictionary.xlsx',index_col = 0).index)\n",
    "uncertainty_dict = set(pd.read_excel('./uncertainty_dictionary.xlsx', index_col = 0).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33fe8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bd4cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(max_row):\n",
    "    #print(i)\n",
    "    file_name = './form/form' + str(i)\n",
    "    text = open(file_name,'r').read()\n",
    "    print('reading..',end = \" \")\n",
    "    df.loc[i] = np.zeros(42)\n",
    "    # other variable per sections\n",
    "    for j in range(3):\n",
    "        if i in [63,64]:\n",
    "            continue\n",
    "        print(i,j,sep= '|',end = \" \")\n",
    "        exp = r\".*(?P<start>ITEM [\\d]\\. \" + re.escape(section[j]) + r\")(?P<MDA>.*)(?P<body>[\\s\\S]*)(?P<end>ITEM \\d|SIGNATURES)\"\n",
    "        regexp = re.compile(exp)\n",
    "        s = regexp.search(text)\n",
    "        \n",
    "        if s:\n",
    "            data = s.group('body')\n",
    "            text = denoise_text(data)\n",
    "            sent_list = sent_tokenize(text)\n",
    "            sentence_length = len(sent_list)\n",
    "\n",
    "            sample = text.split()\n",
    "            sample = normalize(sample)\n",
    "            word_count = len(sample)\n",
    "            complex_word_count = 0\n",
    "            \n",
    "            for word in sample:\n",
    "                if nsyl(word.lower()) > 2:\n",
    "                    complex_word_count += 1\n",
    "            \n",
    "            average_sentence_length = word_count/sentence_length\n",
    "            percentage_of_complex_words = complex_word_count/word_count\n",
    "            fog_index = 0.4 * (average_sentence_length + percentage_of_complex_words)\n",
    "            \n",
    "            positive_score = 0\n",
    "            negative_score = 0\n",
    "            uncertainty_score = 0\n",
    "            constraining_score = 0\n",
    "            for word in sample:\n",
    "                if word in master_dict.index:\n",
    "                    #print(\"is here\")\n",
    "                    if master_dict.loc[word].Positive > 0:\n",
    "                        #print(\"positive\")\n",
    "                        positive_score += 1\n",
    "                    if master_dict.loc[word].Negative > 0:\n",
    "                        negative_score += 1\n",
    "                    if word in uncertainty_dict:\n",
    "                        uncertainty_score += 1\n",
    "                    if word in constraining_dict:\n",
    "                        constraining_score += 1\n",
    "            #print(positive_score)\n",
    "            polarity_score = (positive_score-negative_score)/(positive_score + negative_score + .000001)\n",
    "            positive_word_proportion = positive_score/word_count\n",
    "            negative_word_proportion = negative_score/word_count\n",
    "            uncertainty_word_proportion = uncertainty_score/word_count\n",
    "            constraining_word_proportion = constraining_score/word_count\n",
    "            \n",
    "            df.loc[i][section_name[j].lower() + \"_positive_score\"] = positive_score\n",
    "            df.loc[i][section_name[j].lower() + \"_negative_score\"] = negative_score\n",
    "            df.loc[i][section_name[j].lower() + \"_polarity_score\"] = polarity_score\n",
    "            df.loc[i][section_name[j].lower() + \"_average_sentence_length\"] = average_sentence_length\n",
    "            df.loc[i][section_name[j].lower() + \"_percentage_of_complex_words\"] = percentage_of_complex_words\n",
    "            df.loc[i][section_name[j].lower() + \"_fog_index\"] = fog_index\n",
    "            df.loc[i][section_name[j].lower() + \"_complex_word_count\"] = complex_word_count\n",
    "            df.loc[i][section_name[j].lower() + \"_word_count\"] = word_count\n",
    "            df.loc[i][section_name[j].lower() + \"_uncertainty_score\"] = uncertainty_score\n",
    "            df.loc[i][section_name[j].lower() + \"_constraining_score\"] = constraining_score\n",
    "            df.loc[i][section_name[j].lower() + \"_positive_word_proportion\"] = positive_word_proportion\n",
    "            df.loc[i][section_name[j].lower() + \"_negative_word_proportion\"] = negative_word_proportion\n",
    "            df.loc[i][section_name[j].lower() + \"_uncertainty_word_proportion\"] = uncertainty_word_proportion\n",
    "            df.loc[i][section_name[j].lower() + \"_constraining_word_proportion\"] = constraining_word_proportion        \n",
    "        \n",
    "                \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5db5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(max_row):\n",
    "    print(i,end = \" \")\n",
    "    file_name = './form/form' + str(i)\n",
    "    text = open(file_name,'r').read()\n",
    "    print('reading..',end = \" \")\n",
    "    \n",
    "    #constraining_words_whole_report\n",
    "    constraining_words_whole_report.loc[i] = 0\n",
    "    constraining_words_whole_report_count = 0\n",
    "    for word in denoise_text(text).split():\n",
    "        if word in constraining_dict:\n",
    "            constraining_words_whole_report_count += 1\n",
    "    print('here...',end = \"  \")\n",
    "    constraining_words_whole_report.loc[i] = constraining_words_whole_report_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e394ebb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joing the files for output formate\n",
    "\n",
    "df = pd.concat([cik_list,df,constraining_words_whole_report], axis = 1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fe83f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0f946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('./output.xlsx')\n",
    "df.to_excel(writer, sheet_name='output')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
